\section{Датасет} \label{datasets}

В своей работе я использовал два датасета с SMT-формулами:

\begin{enumerate}
    \item Бенчмарк\footnote{Набор данных для тестирования корректности или производительности программы.} с SMT-COMP 2023 \cite{smt-comp-2023-benchmarks}.
    \item Формулы, собранные в процессе работы дважды упомянутого выше символьного движка USVM \cite{usvm-diploma}.
\end{enumerate}

\subsection{SMT-COMP}

В процессе исследований этот бенчмарк был поделен на три части:

\begin{enumerate}
    \item \texttt{BitVec} --- формулы из логики \texttt{QF\_BV}, обычные формулы с битовыми векторами;
    \item \texttt{SymbEx} --- формулы из логик \texttt{QF\_BV}, \texttt{QF\_ABV}, \texttt{QF\_ABVFP}, \texttt{QF\_AUFBV}, \\ \texttt{QF\_AUFBVFP}, \texttt{QF\_BVFP}, \texttt{QF\_FP}, \texttt{QF\_UF}, \texttt{QF\_UFBV} и \texttt{QF\_UFFP}, которые возникают в процессе работы любого движка для символьного исполнения;
    \item \texttt{QuaFree} --- формулы из всех безкванторных логик, включая \texttt{QF\_LIA}, \texttt{QF\_NRA}, \texttt{QF\_BVFPLRA} и т. д..
\end{enumerate}

Такое разделение обусловлено тем, что для анализа качества хочется смотреть, как модель обучается и какое качество она выдаёт на формулах из разных логик. Однако, к сожалению, большинство логик в данном бенчмарке содержат слишком мало данных, чтобы можно было провести анализ на них, поэтому было принято решение объединить логики в группы по смыслу. Логика \texttt{QF\_BV} была вынесена в отдельную группу, поскольку она является самой многочисленной, а также самой важной на практике. Логики из группы \texttt{SymbEx} были собраны вместе, поскольку моя текущая задача существует в контексте символьного исполнения, поэтому хочется отдельно анализировать способность модели решать подобные формулы. В оставшуюся группу \texttt{QuaFree} попали все безкванторные логики, так как хочется также анализировать способность модели решать задачу в некотором общем случае. В дальнейшем каждую группу будем называть датасетом с соответствующим именем.

Формулы с кванторами в данной работе не рассматривались вообще, поскольку они существенно сложнее безкванторных, и их было решено отложить до лучших времён.

Чтобы данные влезли на видеокарту в каждом датасете были оставлены только формулы размером\footnote{Размером формулы считаем количество переменных, констант и операций в ней. Например, размер формулы $(x + y = 5) \vee (z = 3)$ равен 9.} не более 10\,000 и глубиной\footnote{Глубиной формулы считаем максимальную вложенность переменных, констант и операций в ней. Например, глубина формулы $(x + y = 5) \vee (z = 3)$ равна 4.} не более 2\,000. Итоговые параметры построенных датасетов отображены в таблице~\ref{smt-comp-datasets-table}.

\begin{table}[ht]
\begin{center}
\begin{tabular}{r|cccc}
    Датасет & \makecell{Количество \\ формул} & \makecell{Средний \\ размер \\ формулы} & \makecell{Средняя \\ глубина \\ формулы} & \makecell{Доля \\ выполнимых \\ формул} \\
    \hline \hline
    \rule{0pt}{2.5ex}
    \texttt{BitVec}  &  33\,797 & 1181.92 & 85.45 & 0.378 \\
    \texttt{SymbEx}  &  85\,078 &  669.46 & 49.24 & 0.610 \\
    \texttt{QuaFree} & 123\,396 &  965.16 & 48.71 & 0.622 \\
\end{tabular}
\caption{\label{smt-comp-datasets-table} Параметры датасетов, полученных из данных с SMT-COMP 2023 \cite{smt-comp-2023-benchmarks}.}
\end{center}
\end{table}

\subsection{USVM} \label{usvm-datasets-desc}

% todo: написать, что идея брать эти формулы взята из fast smt

Для проверки возможности применения модели на практике были также вручную собраны датасеты, состоящие из формул, которые возникают в процессе работы символьного движка USVM \cite{usvm-diploma}. Сбор осуществлялся с помощью простого логирования формул, на которых вызывался SMT-решатель. Разные датасеты получались при запуске движка на разных проектах или наборах программ. Подобным образом были собраны три тренировочных и восемнадцать валидационных датасетов.

Такое строгое разделение на тренировочные и валидационные датасеты вдобавок к такому большому количеству вторых обусловлено желанием проверить обобщающую способность модели: хочется, чтобы модель показывала хорошее качество на формулах, возникающих при запуске движка на любых программах; при этом, нет никаких гарантий, что при переходе от одного набора программ к другому распределение, из которого порождаются формулы, изменится несущественно, и качество модели, обученной на данных из другого распределения, упадёт не слишком сильно.

Тренировочные датасеты были собраны на следующих программах:

\begin{enumerate}
    \item \texttt{usvm-test} --- на наборе программ для unit и интеграционного тестирования USVM;
    \item \texttt{the-algorithms} --- на репозитории с реализациями различных теоретических и практических алгоритмов на Java;
    \item \texttt{usvm-core} --- на ядре символьного движка USVM (движок был запущен на самом себе).
\end{enumerate}

Параметры тренировочных датасетов указаны в таблице~\ref{usvm-train-datasets-table}.

\begin{table}[ht]
\begin{center}
\begin{tabular}{r|cccc}
    Датасет & \makecell{Количество \\ формул} & \makecell{Средний \\ размер \\ формулы} & \makecell{Средняя \\ глубина \\ формулы} & \makecell{Доля \\ выполнимых \\ формул} \\
    \hline \hline
    \rule{0pt}{2.5ex}
    \texttt{usvm-test}      & 153\,778 & 522.84 &  5.18 & 0.038 \\
    \texttt{the-algorithms} & 181\,633 & 277.03 & 23.94 & 0.066 \\
    \texttt{usvm-core}      & 192\,744 & 179.42 & 12.19 & 0.066 \\
\end{tabular}
\caption{\label{usvm-train-datasets-table} Параметры тренировочных датасетов, собранных в процессе работы USVM.}
\end{center}
\end{table}

Валидационные датасеты были собраны при запуске USVM на следующих проектах, написанных на Java и других JVM-языках:

\begin{enumerate}
    \item \texttt{owasp} --- OWASP\footnote{Open Web Application Security Project.}, открытый бенчмарк из программ на Java, на котором оценивают качество инструментов для автоматического поиска уязвимостей в коде \cite{owasp-website};
    \item \texttt{cassandra} --- Apache Cassandra, распределённая NoSQL СУБД\footnote{Система Управления Базами Данных.} \cite{cassandra-website};
    \item \texttt{kafka} --- Apache Kafka, распределённый брокер сообщений \cite{kafka-website};
    \item \texttt{spark-core} --- Apache Spark, система для распределённой обработки данных (модуль ядра) \cite{spark-website};
    \item \texttt{spark-streaming} --- тот же Spark (модуль потоковой обработки данных);
    \item \texttt{utbot-core} --- UnitTestBot, инструмент для автоматической генерации unit-тестов (модуль ядра) \cite{utbot-github};
    \item \texttt{utbot-java} --- тот же UnitTestBot (модуль генерации тестов для Java);
    \item \texttt{utbot-python} --- тот же UnitTestBot (модуль генерации тестов для Python);
    \item \texttt{utbot-js} --- тот же UnitTestBot (модуль генерации тестов для языка JavaScript);
    \item \texttt{utbot-go} --- тот же UnitTestBot (модуль генерации тестов для Go);
    \item \texttt{zookeeper} --- Apache Zookeeper, служба для координации распределённых систем \cite{zookeeper-website};
    \item \texttt{elasticsearch} --- Elasticsearch, встраиваимая система для текстового поиска \cite{elasticsearch-website};
    \item \texttt{hbase} --- Apache HBase, распределённая табличная база данных \cite{hbase-website};
    \item \texttt{guava} --- Google Guava, набор библиотек-расширений для Java \cite{guava-website};
    \item \texttt{hadoop-common} --- Apache Hadoop, экосистема для распределённого хранения и обработки данных (модуль ядра) \cite{hadoop-website};
    \item \texttt{hadoop-hdfs} --- тот же Hadoop (модуль распределённой файловой системы);
    \item \texttt{hadoop-mapreduce} --- тот же Hadoop (модуль для распределённых вычислений в парадигме MapReduce);
    \item \texttt{hadoop-yarn} --- тот же Hadoop (модуль планировщика ресурсов);
\end{enumerate}

Параметры валидационных датасетов указаны в таблице~\ref{usvm-val-datasets-table}.

\begin{table}[ht]
\begin{center}
\begin{tabular}{r|cccc}
    Датасет & \makecell{Количество \\ формул} & \makecell{Средний \\ размер \\ формулы} & \makecell{Средняя \\ глубина \\ формулы} & \makecell{Доля \\ выполнимых \\ формул} \\
    \hline \hline
    \rule{0pt}{2.5ex}
    \texttt{owasp}            &  30\,935 & 3169.44 &  27.0  & 0.029 \\
    \texttt{cassandra}        &  13\,896 &  164.84 &  11.73 & 0.057 \\
    \texttt{kafka}            &  46\,867 & 5103.27 &  18.93 & 0.083 \\
    \texttt{spark-core}       &  14\,504 & 5599.33 &  28.0  & 0.061 \\
    \texttt{spark-streaming}  &  69\,254 & 1168.64 &  8.31  & 0.057 \\
    \texttt{utbot-core}       &  31\,043 & 4570.6  &  28.95 & 0.061 \\
    \texttt{utbot-java}       &  12\,492 &  116.4  &  10.71 & 0.045 \\
    \texttt{utbot-python}     &  24\,893 &  266.66 &  6.04  & 0.115 \\
    \texttt{utbot-js}         &  13\,276 & 2286.54 & 133.8  & 0.062 \\
    \texttt{utbot-go}         &  43\,988 &  281.69 &  19.21 & 0.014 \\
    \texttt{zookeeper}        &  38\,631 & 1196.51 &  47.23 & 0.046 \\
    \texttt{elasticsearch}    &  38\,967 &  388.62 &  19.72 & 0.001 \\
    \texttt{hbase}            &  38\,049 & 3513.78 &  90.81 & 0.019 \\
    \texttt{guava}            &  56\,607 &  545.98 &  34.99 & 0.014 \\
    \texttt{hadoop-common}    &  41\,255 &  419.05 &  10.32 & 0.081 \\
    \texttt{hadoop-hdfs}      & 109\,294 & 2795.7  & 210.87 & 0.032 \\
    \texttt{hadoop-mapreduce} &  12\,044 & 1294.2  &  47.17 & 0.011 \\
    \texttt{hadoop-yarn}      &  32\,555 &  120.71 &  13.01 & 0.035 \\
\end{tabular}
\caption{\label{usvm-val-datasets-table} Параметры валидационных датасетов, собранных в процессе работы USVM.}
\end{center}
\end{table}

Отмечу, что в валидационных датасетах также отобраны формулы, размер и глубина которых не превышает 10\,000 и 2\,000 соответственно, но, помимо этого, здесь добавилось ещё одно условие: размер должен быть не меньше некоторого значения, которое подбиралось эмпирическим путём отдельно для каждого датасета (обычно оно находилось в районе 200--500, и его можно угадать, если посмотреть на средний столбец в таблице). Поэтому формулы из валидационных датасетов кажутся больше, чем из тренировочных. Это было сделано, чтобы уменьшить объём данных и ускорить вычисления, а также чтобы оценивать качество модели именно на больших формулах, так как кажется, что на практике модель должна существенно помогать движку именно в этом случае.

Ещё внимательный читатель может заметить, что во всех датасетах из формул, собранных в процессе работы USVM, есть огромный дисбаланс классов: меньше десяти процентов формул являются выполнимыми. На самом деле, в этом нет ничего неожиданного, потому что в процессе символьного исполнения программы SMT-решателю действительно чаще всего приходится иметь дело с невыполнимыми формулами.

% todo: кажется, тут стоит ещё дописать

\subsection{Метрики}

Поскольку в работе рассматривается задача бинарной классификации, было принято решение следить за двумя метриками: ROC-AUC (площадь под ROC-кривой, далее будет обозначаться <<ROC-AUC>>) и Average Precision (площадь под precision-recall кривой, далее будет обозначаться <<AP>>) для случая, когда представителями положительного класса считаются выполнимые формулы. Пример на рис.~\ref{roc-auc-vs-au-prc}.

\begin{figure}[!ht]
\begin{center}
    \includegraphics[scale=0.5]{./assets/roc-auc-vs-au-prc.jpg}
    \caption{\label{roc-auc-vs-au-prc} Пример вычисления ROC-AUC и AP. Источник: \url{https://juandelacalle.medium.com/how-and-why-i-switched-from-the-roc-curve-to-the-precision-recall-curve-to-analyze-my-imbalanced-6171da91c6b8} (дата обр. 27.05.2024).}
\end{center}
\end{figure}

Использование ROC-AUC обусловлено тем, что, помимо классификационной, это ещё и ранжирующая метрика, а в работе будет также интересно смотреть и на ранжирующие способности модели. Использование AP обусловлено тем, что ROC-AUC начинает терять репрезентативность, если в выборке данных появляется большой дисбаланс классов \cite{ap-vs-roc-auc-paper}.

Отмечу два факта, которые понадобятся в дальнейшем:

\begin{enumerate}
    \item ROC-AUC для случайного предсказания, а также для предсказания всем примерам положительной или предсказания всем примерам отрицательной метки равен $0.5 \pm \varepsilon$.
    \item AP для случайного предсказания, а также для предсказания всем примерам положительной или предсказания всем примерам отрицательной метки равен $t \pm \varepsilon$, где $t$ --- доля примеров положительного класса в выборке.
\end{enumerate}

Исходя из этого, можно для каждого датасета посчитать базовые значения метрик и сравнивать полученные результаты с ними, чтобы показать, что решение имеет хоть какой-то смысл.

Таким образом, в представленных результатах будет указано по два значения ROC-AUC и AP --- базовое, которое вычислено согласно только что изложенным фактам, и тестовое, которое получено при валидации обученной ранее модели на этом датасете. В таблицах с результатами базовое значение будет называться <<контрольным>>, а полученное при валидации --- <<тестовым>>. Выбранные названия отсылают к описанию результатов A/B-тестов (однако, это только отсылки --- в действительности, никакие A/B-тесты в данной работе не проводились).

Помимо этого, в одном из экспериментов будет считаться метрика <<precision at fixed recall>>, которая выражает уровень точности при заданном уровне полноты. За этими значениями тоже полезно следить, так как для символьного движка выполнимые формулы (которые в нашей задаче являются представителями положительного класса) гораздо интереснее, чем невыполнимые.

% todo: текстовый подход
% \section{Текстовый подход}

\newpage

\section{Подход с использованием GNN}

\subsection{Архитектура нейронной сети для решения задачи}

Придуманное в ходе работы решение объединяет в себе идеи из всех статей, рассмотренных в главе про обзор литературы и предметной области.

В качестве основной архитектуры для решения задачи была выбрана некоторая аппроксимация \underline{\hyperref[gnn-architecture]{GNN}}, работающая схожим образом с тем, что было ранее описано в разделе \underline{\hyperref[gnn-for-scheduling-of-smt-solvers]{GNN for Scheduling of SMT Solvers}} \cite{gnn-for-scheduling-paper}. Здесь используется такая же схема передачи GNN-сообщений по данному на вход абстрактно-синтаксическому дереву (AST) формулы, превращённому в ориентированный ациклический граф для простоты вычислений, однако всё это происходит с некоторыми отличиями:

\begin{enumerate}
    \item рёбра проводятся только в направлении от операндов к операторам (см. пример ниже);
    \item обновление эмбеддингов состояний вершин начинается от истоков графа (листьев AST формулы) и производится в порядке топологической сортировки;
    \item передача векторов-сообщений происходит согласно ориентации рёбер (от начала к концу);
    \item вычисление состояния каждой вершины производится ровно один раз и только после вычисления состояний всех вершин, от которых она зависит, т. е. всех других вершин, из которых есть ребро в неё;
    \item указанные вычисления для всех вершин делаются за один проход по формуле;
    \item в конце в качестве итогового вектора-представления формулы используется вектор-состояние стока графа (корневой вершины формулы).
\end{enumerate}

Для лучшего понимания, на рис.~\ref{formula-ast-message-flow} изображён пример графа и того, в каком порядке производятся вычисления состояний вершин.

\begin{figure}[H]
\begin{center}
    \includegraphics[scale=0.95]{./assets/formula-ast-message-flow.pdf}
    \caption{\label{formula-ast-message-flow} Пример ориентированного ациклического графа, полученного из AST формулы $(\texttt{0x40} \le x) \wedge (\texttt{0x40} \le y) \wedge ((x + y) \times \texttt{0x02} < \texttt{0x02})$ в логике вычислений с восьмибитными векторами. Вершины разбиты по уровням согласно порядку вычислений состояний: снизу истоки (листья) --- с них начинается вычисление, сверху сток (корень) --- его вектор вычисляется последним, и он же считается итоговым вектором-представлением всей формулы. Начертание каждого ребра отражает момент, в который по нему производится передача сообщения: по рёбрам, нарисованным штриховой линией (- - -) передача производится на первом шаге, штрих-пунктирной линией (- $\cdot$ -) --- на втором, пунктирной линией ($\cdot$ $\cdot$ $\cdot$) --- на третьем, а сплошной (\sout{\ \ \ \ \ }) --- на четвёртом. Петли в данном графе обозначают, что для вычисления состояния вершины также используется её начальное состояние (об этом подробнее написано в параграфах про начальные состояния вершин и вычисление их состояний).}
\end{center}
\end{figure}

Описанная выше структура была придумана мной при попытке оптимизировать методы вычислений из статьи \cite{gnn-for-scheduling-paper}, чтобы все нужные состояния можно было посчитать за один проход по AST формулы. Тем не менее, позже, в процессе очередной итерации исследования предметной области, выяснилось, что такая архитектура была придумана ещё в 1997 году, описана в статьях \cite{rvnn-intro-paper} и \cite{rvnn-intro-paper-2} и более известна как рекурсивная нейронная сеть или RvNN\footnote{От англ. \textit{Recursive Neural Network}.}. Авторы указанных статей пытались изобрести подход к обучению моделей для иерархически устроенных данных (рис.~\ref{rvnn-data-tree}), чтобы можно было учитывать и их специфику наряду с тем, как это происходит в свёрточных сетях для данных в виде картинок или в рекуррентных сетях для данных в виде последовательностей. В итоге, было предложено использовать процедуру, похожую на передачу сообщений в GNN, применительно к дереву или ориентированному ациклическому графу, задающим саму иерархию в данных. В статье даже в качестве одного из примеров таких данных рассматриваются логические термы (рис.~\ref{rvnn-term-dag}).

\begin{figure}[!ht]
\begin{center}
    \includegraphics[scale=0.45]{./assets/rvnn-data-tree.png}
    \caption{\label{rvnn-data-tree} Пример иерархически устроенных данных: анамнез пациента. Картинка взята из статьи \cite{rvnn-intro-paper}.}
\end{center}

\begin{center}
    \includegraphics[scale=0.2]{./assets/rvnn-term-dag.png}
    \caption{\label{rvnn-term-dag} Пример представления логического терма $\phi(\alpha, \psi(\gamma), \psi(\gamma, \phi(\alpha, \beta)))$ в виде ориентированного ациклического графа. Картинка взята из статьи \cite{rvnn-intro-paper-2}.}
\end{center}
\end{figure}

Однако с ростом доступных вычислительных мощностей данный подход уступил более обобщённому подходу с использованием GNN и не получил активного дальнейшего развития.

Посчитанный в ходе описанных выше действий вектор-представление графа считается эмбеддингом формулы, который потом можно передать в MLP для предсказания различных параметров формулы, например, её выполнимости. Именно так делается у меня, и ровно так же было предложено делать в статье \cite{rvnn-intro-paper} (рис.~\ref{rvnn-process}).

\begin{figure}[ht]
\begin{center}
    \includegraphics[scale=0.25]{./assets/rvnn-process.png}
    \caption{\label{rvnn-process} Общий подход к решению задачи предсказания произвольных параметров ориентированного ациклического графа. Картинка взята из статьи \cite{rvnn-intro-paper}.}
\end{center}
\end{figure}

\subsection{Начальные состояния вершин} \label{vertex-initial-states}

Выше написано, что в вычислениях участвуют начальные векторы-состояния вершин, но до этого момента не было сказано, откуда они берутся.

С начальными векторами вершин-операций всё легко: эмбеддинг для каждой из них просто выучивается, как это делается, например, для слов в задаче обработки естественного языка, и сохраняются в специальную таблицу. Замечу, что на этом этапе можно сделать разделение одной операции, работающей с разными типами данных, на разные, чтобы учесть отличия в механизме их работы. Например, сложение целых чисел, сложение вещественных чисел и сложение битовых векторов можно считать разными операциями.

С начальными векторами вершин-переменных и вершин-констант всё куда сложнее. Начальный вектор для вершины-переменной должен содержать некоторую информацию о том, что эта вершина соответствует переменной определённого типа, однако с этим есть несколько проблем. Во-первых, векторы, кодирующие разные переменные должны отличаться друг от друга, чтобы как-то отразить то, что в выполняющем наборе формулы им могут быть присвоены разные значения. Во-вторых, эти векторы нельзя основывать на информации об именах переменных, поскольку обычно имя переменной не несёт в себе никакого смысла и используется для разделения переменных внутри одной формулы, да и сами логические формулы инвариантны относительно переименования переменных.

В процессе работы было придумано три возможных варианта действий с переменными:

\begin{enumerate}
    \item Можно проигнорировать все имена переменных в формуле, оставив только информацию об их типе. После такого преобразования все переменные можно считать конструкциями вида \texttt{Var[Тип]}, поэтому в формуле вместо имён переменных будут записи \texttt{Var[Integer]}, \texttt{Var[Real]}, \texttt{Var[BitVec<8>]}, \texttt{Var[Array<BitVec<12>, Float64>]} и прочие подобные. Таких записей будет немного, поэтому для них можно выучить эмбеддинги подобно тому, как это делается для вершин-операций. Такой подход не учитывает различия между переменными, однако позволяет представить формулу в хоть каком-нибудь виде. Например, в формуле на рис.~\ref{formula-ast-message-flow} у переменных $x$ и $y$ будет одинаковое начальное состояние, соответствующее эмбеддингу, выученному для записи \texttt{Var[BitVec<8>]}.
    \item Можно завести отдельную табличку с набором эмбеддингов для переменных и на каждом запуске модели при обучении или при использовании выдавать каждой переменной случайный эмбеддинг из этого набора. Такая схема будет предоставлять разные векторы разным переменным и не будет привязывать их к именам этих переменных, чтобы учесть свойство инвариантности формул относительно переименования. Предполагается, что процессе обучения векторы будут сходиться к случайным точкам, которые достаточно хорошо описывают семантику переменных, а модель научится определённым образом подстраиваться под эту случайность. Это даже можно считать способом регуляризацией модели.
    \item Помимо этого, можно сделать так же, как в предыдущем пункте, но не выучивать табличку с эмбеддингами, а вместо этого случайным образом нумеровать переменные натуральными числами, после чего для этих номеров применять технику позиционного кодирования (англ. \textit{positional encoding}) из знаменитой статьи <<Attention Is All You Need>> \cite{attention-is-all-you-need}. Идея работает такая же, как и пункт 2, но имеет меньше обучаемых параметров и потенциально лучше обобщается на формулы большого размера.
\end{enumerate}

Если про технику работы с переменными всё более-менее понятно (хотя бы понятно, в каком направлении развивать решение), то константы в формуле представляют настоящую проблему, так как нужно научиться переводить и целые числа, и вещественные числа, и битовые векторы, и массивы значений в некоторое многомерное пространство с сохранением всей семантики: абсолютных значений, отношений больше-меньше, внутренней структуры (для битовых векторов и массивов). Задача построения такого представления оказалась слишком сложной, и за время работы не было придумано никаких методов, которые, в теории, могли бы дать существенный прирост качества. Тем не менее, здесь также можно выписать три варианта, что можно сделать с кодированием констант:

\begin{enumerate}
    \item Можно поступить аналогично первому варианту подхода к переменным --- убрать значения всех констант и оставить вместо них только конструкции вида \texttt{Val[Тип]}, после чего обучать эмбеддинги для этих конструкций. Например, в формуле на рис.~\ref{formula-ast-message-flow} у значений \texttt{0x02} и \texttt{0x40} будет одинаковое начальное состояние, соответствующее эмбеддингу, выученному для записи \texttt{Val[BitVec<8>]}.
    \item Можно воспользоваться способом, предложенным в статье \cite{embeddings-for-numerical-features-paper} --- разбивать пространство значений, из которого приходит константа (например, для вещественной переменной это будет вещественная прямая), на группы (бины) и строить вектор, как это показано на рис.~\ref{linear-bins-for-values}. Такой способ, к сожалению, не применим для битовых векторов, так как они могут иметь произвольный размер, а без априорного знания про этот размер отобразить вектор в линейное пространство с сохранением семантики всех операций невозможно.
    \item Помимо этого, можно воспользоваться техникой под названием Fourier Feature Mapping \cite{ffm-paper-1} \cite{ffm-paper-2} --- вторым способом, предложенным в статье \cite{embeddings-for-numerical-features-paper}. Эта статья исследует способы кодирования семантики произвольных числовых значений и ставит своей целью приблизить нейронные сети к градиентным бустингам по качеству решения задач табличного машинного обучения. Насколько я понял, техника заключается в вычислении некоторого количества дискретных преобразований Фурье с разными частотами и использовании полученных значений в качестве координат вектора-эмбеддинга.
\end{enumerate}

\begin{figure}[ht]
\begin{center}
    \includegraphics[scale=0.25]{./assets/linear-bins-for-values.png}
    \caption{\label{linear-bins-for-values} Построение эмбеддинга вещественной константы с помощью бинов. Картинка взята из статьи \cite{embeddings-for-numerical-features-paper}.}
\end{center}
\end{figure}

\subsection{Вычисление состояний вершин}

Теперь пришло время поговорить про то, каким способом, собственно, вычислять вектор-состояние очередной вершины. Согласно схеме обновления состояний в GNN это должно происходить посредством передачи векторов-сообщений от соседних вершин. Осталось только выбрать, какие функции подставить в формулу~(\ref{gnn-state-update-rule}). В экспериментах участвовали два варианта.

\subsubsection{SAGE Convolution} \label{sage-conv-desc}

Первый был представлен в статье \cite{sage-conv-paper} и называется GraphSAGE. В нём вычисление происходит согласно формуле~(\ref{sage-conv-update-formula}), где $x_v$ --- изначальное состояние вершины $v$, а $x_v'$ --- новое, которое вычисляется в процессе.

\begin{equation} \label{sage-conv-update-formula}
    x_v' = \sigma \left(W_3 \cdot \left(W_1 \cdot x_v + W_2 \cdot \underset{u \in \mathcal{N}(v)}{\text{\textsc{mean}}} x_u \right) + b \right)
\end{equation}

Здесь $\mathcal{N}(v)$ --- окрестность вершины $v$, функция \textsc{mean} обозначает взятие среднего значения по указанному множеству, $\sigma$ --- сигмоидная функция\footnote{$\sigma(x) = \dfrac{1}{1 + e^{-x}}$}, а матрицы $W_1$, $W_2$, $W_3$ и вектор $b$ являются выучиваемыми параметрами сети.

\subsubsection{Transformer Convolution} \label{transformer-conv-desc}

Второй подход был представлен в статье \cite{transformer-conv-paper} и называется Transformer Graph Convolution. В нём вычисление происходит согласно формулам (\ref{transformer-conv-update-formula-att-coefs}) и (\ref{transformer-conv-update-formula}).

\begin{equation} \label{transformer-conv-update-formula-att-coefs}
    \alpha_{u} = \underset{u \in \mathcal{N}(v)}{\text{\textsc{softmax}}} \left[\frac{(W_3 \cdot x_v)^T (W_4 \cdot x_u)}{\sqrt d} \right]
\end{equation}

\begin{equation} \label{transformer-conv-update-formula}
    x_v' = W_1 \cdot x_v + \sum_{u \in \mathcal{N}(v)} \alpha_u W_2 \cdot x_u
\end{equation}

Здесь $d$ --- размерность участвующих в вычислениях векторов, функция \textsc{softmax} по указанному множеству обозначает softmax-преобразование\footnote{$\text{\textsc{softmax}}(a_1, a_2, \ldots, a_n)_k = \dfrac{e^{a_k}}{\sum \limits_{i = 1}^n e^{a_i}}$} чисел этого множества, а матрицы $W_1$, $W_2$, $W_3$ и $W_4$ являются выучиваемыми параметрами сети.

Нетрудно заметить, что механизм вычислений похож на тот, что используется в архитектуре Transformer \cite{attention-is-all-you-need} (собственно, оттуда и название подхода): значения $\alpha$ являются коэффициентами механизма внимания, матрица $W_3$ формирует вектор-запрос, $W_4$ --- вектор-ключ, а $W_2$ --- вектор-значение.

\subsubsection{Учёт начального состояния вершины}

Из формул (\ref{sage-conv-update-formula}) и (\ref{transformer-conv-update-formula}) видно, что для вычисления вектора-состояния вершины используется её же начальное состояние (в указанных формулах оно домножается на матрицу $W_1$). Именно таким образом и происходит учёт информации об операции, которой соответствует вершина: изначально в вершину кладётся вектор, представляющий семантику этой операции, а потом он используется при вычислении состояния этой вершины через состояния её детей. Петли в графе на рис.~\ref{formula-ast-message-flow} обозначают в точности это.

\subsection{Классификатор и функция потерь}

С точки зрения нейронной сети задача поставлена как задача классификации, поэтому после прохода по графу и вычисления всех состояний вектор-состояние корневой вершины отправляется в классификатор, который представляет из себя нейронную сеть с четырьмя полносвязными слоями и слоями активации ReLU между ними.

В качестве функции потерь используется бинарная кросс-энтропия.

\newpage

\section{Эксперименты и результаты}

% todo: тут в основной части можно красивый барплот, а в приложении огромную таблицу

К сожалению, из-за присутствовавших трудностей с вычислительными мощностями все эксперименты проводились с использованием векторов-состояний вершин размера исключительно 32 (другие размеры попробовать не удалось), а из описанных в разделе~\ref{vertex-initial-states} методов построения начальных состояний вершин были попробованы только первые методы построения состояний для переменных и констант. Однако, даже с такими подходами удалось провести ряд экспериментов и получить некоторые практически значимые результаты.

\subsection{Первый эксперимент}

В первом эксперименте была предпринята попытка обучить модель с архитектурой SAGE Convolution, описанной в разделе~\ref{sage-conv-desc}, на датасетах из формул с SMT-COMP (таблица~\ref{smt-comp-datasets-table}).

Для полноты картины эксперимент был устроен следующим образом: было обучено три модели (по одной на каждом из датасетов), после чего для каждой полученной модели считались метрики на её обучающем датасете, на его частных случаях (например, \texttt{BitVec} $\subset$ \texttt{SymbEx}) или на его альтернативных вариантах (например, для \texttt{SymbEx} был взят датасет \texttt{usvm-test}, из формул, собранных с символьной машины \cite{usvm-diploma}). Это сделано, чтобы, в том числе, узнать, может ли знание о более сложных формулах помочь модели разбираться с более простыми.

Разумеется, в случае, когда модель обучалась на датасете \texttt{X}, подсчёт метрик на этом датасете производится на специально отложенной тестовой выборке\footnote{В этом и во всех последующих экспериментах в каждом датасете примерно 15\% формул были отложены в валидационную выборку, и ещё примерно 10\% --- в тестовую.}. Если датасет \texttt{X} не участвовал в обучении модели, то метрики считались на всех его данных. Это соблюдается в этом и во всех последующих экспериментах.

Обучение каждой модели производилось в течение 50 эпох с помощью оптимизатора Adam \cite{adam-paper} с learning rate\footnote{Так называют длину шага градиентного спуска.}, изначально равным $10^{-4}$, и управляемым согласно динамическому расписанию \textit{Reduce LR On Plateau}.

В течение всего обучения проводился отбор лучших моделей (англ. \textit{model selection}) по значению функции потерь на валидационной выборке.

Результаты отображены в таблице~\ref{smt-comp-val-results}. К сожалению, они получились не особо впечатляющими --- во время обучения даже на тренировочном датасете функция потерь упиралась в границу, которую никак не могла преодолеть, так что модель выглядит недообученной. Оно и понятно --- модель не умеет отличать переменные друг от друга и не понимает семантику констант в формуле.

\begin{table}[ht]
\begin{center}
\begin{tabular}{c|c||cc|cc}
    \makecell{Трен. \\ датасет} & \makecell{Вал. \\ датасет} & \makecell{Контр-ный \\ \textsc{ROC-AUC}} & \makecell{Тестовый \\ \textsc{ROC-AUC}} & \makecell{Контр-ный \\ \textsc{AP}} & \makecell{Тестовый \\ \textsc{AP}} \\
    \hline \hline
    \rule{0pt}{2.5ex}
    \texttt{BitVec}  & \texttt{BitVec}     & 0.500 & 0.718 & 0.378 & 0.695 \\
    \hline
    \texttt{SymbEx}  & \texttt{BitVec}     & 0.500 & 0.548 & 0.378 & 0.426 \\
                     & \texttt{SymbEx}     & 0.500 & 0.358 & 0.610 & 0.678 \\
                     & \texttt{usvm-test}  & 0.500 & 0.503 & 0.038 & 0.054 \\
    \hline
    \texttt{QuaFree} & \texttt{BitVec}     & 0.500 & 0.719 & 0.378 & 0.706 \\
                     & \texttt{SymbEx}     & 0.500 & 0.592 & 0.610 & 0.716 \\
                     & \texttt{QuaFree}    & 0.500 & 0.564 & 0.622 & 0.705 \\
\end{tabular}
\caption{\label{smt-comp-val-results} Метрики, полученные при обучении SAGE Convolution на датасетах с SMT-COMP \cite{smt-comp-2023-benchmarks}.}
\end{center}
\end{table}

\subsection{Второй эксперимент}

Второй эксперимент заключался в обучении модели с той же архитектурой, что и в первом эксперименте, но уже на других датасетах. В этот раз были рассмотрены датасеты из формул, собранных с символьного движка USVM \cite{usvm-diploma} (таблица~\ref{usvm-train-datasets-table}).

Аналогично первому эксперименту, здесь модель обучалась на каком-то датасете, после чего валидировалась, в том числе, на некоторых других датасетах, однако на этот раз валидационные датасеты, в основном, не пересекались с тренировочными. Сделано это было, чтобы можно было оценить обобщающую способность модели. Подробнее об этом было написано во втором абзаце раздела~\ref{usvm-datasets-desc}.

Обучение каждой модели производилось в течение 30 эпох с помощью оптимизатора AdamW \cite{adamw-paper} с параметром weight decay\footnote{Параметр отвечает за регуляризацию модели на основе штрафа за слишком большие абсолютные значения весов.}, равным $10^{-3}$, и learning rate, изначально равным $10^{-4}$, и управляемым согласно динамическому расписанию \textit{Reduce LR On Plateau}. Такое большое значение weight decay было продиктовано желанием как можно сильнее повысить обобщающую способность модели, чтобы она потенциально могла показывать хорошее качество на данных из другого распределения.

В течение всего обучения проводился отбор лучших моделей по значению функции потерь на валидационной выборке.

Результаты в таблице~\ref{usvm-train-ds-val-results}.

\begin{table}[ht]
\begin{center}
\begin{tabular}{c|c||cc|cc}
    \makecell{Трен. \\ датасет} & \makecell{Вал. \\ датасет} & \makecell{К. \\ \textsc{ROC-AUC}} & \makecell{Т. \\ \textsc{ROC-AUC}} & \makecell{К. \\ \textsc{AP}} & \makecell{Т. \\ \textsc{AP}} \\
    \hline \hline
    \rule{0pt}{2.5ex}
    \texttt{usvm-test} & \texttt{usvm-test}      & 0.500 & 0.873 & 0.038 & 0.566 \\
    \cline{2-6}
    \rule{0pt}{2.5ex}
                       & \texttt{the-algorithms} & 0.500 & 0.551 & 0.066 & 0.067 \\
    \cline{2-6}
    \rule{0pt}{2.5ex}
                       & \texttt{usvm-core}      & 0.500 & 0.641 & 0.066 & 0.087 \\
    \cline{2-6}
    \rule{0pt}{2.5ex}
                       & \texttt{owasp-all}      & 0.500 & 0.314 & 0.029 & 0.101 \\
    \hline
    \makecell{
        \texttt{usvm-test} \& \\
        \texttt{the-algorithms}
    } & \makecell{
        \texttt{usvm-test} \& \\
        \texttt{the-algorithms}
    }                      & 0.500 & 0.786 & 0.053 & 0.447 \\
    \cline{2-6}
    \rule{0pt}{2.5ex}
      & \texttt{usvm-core} & 0.500 & 0.833 & 0.066 & 0.198 \\
    \cline{2-6}
    \rule{0pt}{2.5ex}
      & \texttt{owasp-all} & 0.500 & 0.636 & 0.029 & 0.260 \\
    \hline
    \makecell{
        \texttt{usvm-test} \& \\
        \texttt{the-algorithms} \& \\
        \texttt{usvm-core}
    } & \makecell{
        \texttt{usvm-test} \& \\
        \texttt{the-algorithms} \& \\
        \texttt{usvm-core}
    }                      & 0.500 & 0.821 & 0.058 & 0.593 \\
    \cline{2-6}
    \rule{0pt}{2.5ex}
      & \texttt{owasp-all} & 0.500 & 0.958 & 0.029 & 0.873 \\
\end{tabular}
\caption{\label{usvm-train-ds-val-results} Метрики, полученные при обучении SAGE Convolution на датасетах, собранных с USVM \cite{usvm-diploma}. Символ <<\&>> здесь обозначает объединение датасетов. <<К.>> обозначает контрольное значение, <<Т.>> --- тестовое.}
\end{center}
\end{table}

Здесь метрики выглядят куда интереснее, чем в первом эксперименте. Во-первых, полученные числа сами по себе выглядят более солидно. Во-вторых, хорошо видно, как растёт обобщающая способность модели, если обучать её на более сложных и разнообразных формулах. Особенно, это заметно по метрикам на датасете \texttt{owasp-all} (версия датасета \texttt{owasp}, из которой не убирали формулы слишком маленького размера).

\subsection{Третий эксперимент}

Удачные результаты второго эксперимента (особенно полученные на датасете \texttt{owasp-all}) натолкнули на мысль, что, возможно, последняя обученная модель (нижняя в таблице~\ref{usvm-train-ds-val-results}) уже достаточно хороша, чтобы уметь предсказывать ответ для формул, возникающих в процессе анализа \textit{произвольных} программ с помощью символьного движка USVM.

Для проверки этой гипотезы были собраны датасеты из формул, возникших в процессе анализа разных проектов с открытым исходным кодом, написанных на JVM-языках (таблица~\ref{usvm-val-datasets-table}), и на них были посчитаны уже знакомые нам метрики. Результаты в таблице~\ref{usvm-val-results-roc-auc-avg-prec}.

\begin{table}[ht]
\begin{center}
\begin{tabular}{r|cc|cc}
    Датасет & \makecell{Контрольный \\ \textsc{ROC-AUC}} & \makecell{Тестовый \\ \textsc{ROC-AUC}} & \makecell{Контрольный \\ \textsc{AP}} & \makecell{Тестовый \\ \textsc{AP}} \\
    \hline \hline
    \rule{0pt}{2.5ex}
    \texttt{BitVec}           & 0.500 & 0.613 & 0.378 & 0.484 \\
    \texttt{SymbEx}           & 0.500 & 0.509 & 0.610 & 0.628 \\
    \hline
    \texttt{owasp}            & 0.500 & 0.914 & 0.029 & 0.245 \\
    \texttt{cassandra}        & 0.500 & 0.956 & 0.057 & 0.603 \\
    \texttt{kafka}            & 0.500 & 0.827 & 0.083 & 0.689 \\
    \texttt{spark-core}       & 0.500 & 0.970 & 0.061 & 0.616 \\
    \texttt{spark-streaming}  & 0.500 & 0.992 & 0.057 & 0.889 \\
    \texttt{utbot-core}       & 0.500 & 0.982 & 0.061 & 0.657 \\
    \texttt{utbot-java}       & 0.500 & 0.997 & 0.045 & 0.911 \\
    \texttt{utbot-python}     & 0.500 & 0.923 & 0.115 & 0.480 \\
    \texttt{utbot-js}         & 0.500 & 0.801 & 0.062 & 0.307 \\
    \texttt{utbot-go}         & 0.500 & 0.996 & 0.014 & 0.712 \\
    \texttt{zookeeper}        & 0.500 & 0.840 & 0.046 & 0.407 \\
    \texttt{elasticsearch}    & 0.500 & 0.999 & 0.001 & 0.468 \\
    \texttt{hbase}            & 0.500 & 0.824 & 0.019 & 0.083 \\
    \texttt{guava}            & 0.500 & 0.998 & 0.014 & 0.816 \\
    \texttt{hadoop-common}    & 0.500 & 0.975 & 0.081 & 0.714 \\
    \texttt{hadoop-hdfs}      & 0.500 & 0.847 & 0.032 & 0.379 \\
    \texttt{hadoop-mapreduce} & 0.500 & 0.948 & 0.011 & 0.198 \\
    \texttt{hadoop-yarn}      & 0.500 & 0.994 & 0.035 & 0.845 \\
\end{tabular}
\caption{\label{usvm-val-results-roc-auc-avg-prec} Результаты валидации на датасетах из реальных формул, собранных с символьной машины USVM \cite{usvm-diploma} (см. таб.~\ref{usvm-val-datasets-table}).}
\end{center}
\end{table}

Думаю, что результаты достаточно хороши, для того, чтобы их можно было считать в значительной степени положительными, и чтобы полученную модель можно было использовать на практике.

Поскольку обычно в процессе символьного исполнения распознавание выполнимых формул важнее, чем распознавание невыполнимых, я также привожу результаты метрик <<precision @ fixed recall>> (уровень точности при заданном уровне полноты) в таблице~\ref{usvm-val-results-precs-at-recall} в приложении.

Тем не менее, видно, что результаты на датасетах \texttt{BitVec} и \texttt{SymbEx} с SMT-COMP (таблица~\ref{smt-comp-datasets-table}), в которых содержатся формулы из аналогичных логик, оставляют желать лучшего. Так что, скорее всего, высокие результаты на оставшихся датасетах обусловлены, в первую очередь, тем, что в процессе работы движка USVM получаются сильно специфические формулы, по структуре которых легко предсказать их выполнимость. Однако, это не повод не использовать данную особенность при решении практической задачи.

\subsection{Четвёртый эксперимент}

Для полноты исследования было также решено попробовать обучить модель с другой архитектурой (Transformer Convolution из раздела~\ref{transformer-conv-desc}), однако этот эксперимент оказался неудачным.

При обучении на датасетах с SMT-COMP (таблица~\ref{smt-comp-datasets-table}) где-то после седьмой-восьмой эпохи модель начинала бесконтрольно переобучаться (метрики на тренировочном наборе уверенно улучшались, а на валидационном стремительно ухудшались). Причём лучшая модель, полученная на тот момент, всё равно проигрывала модели с архитектурой SAGE Convolution.

Более того, в архитектуру Transformer Convolution встроена возможность использовать механизм dropout \cite{dropout-paper} при обучении, и подобная проблема проявлялась даже при вероятности отключения нейрона $p = 0.2, \ 0.3, \ 0.4, \ 0.5$. Использование техники Layer Normalization \cite{layer-norm-paper}, которая часто помогает при проблемах с обучением механизма внимания, тоже не дало улучшений.

Видимо, действительно, данные в датасетах с SMT-COMP устроены настолько сложно и отражают настолько общий случай, что никакие техники, успешно показывающие себя на датасетах с USVM (раздел~\ref{usvm-datasets-desc}), здесь не работают.

Сами датасеты, собранные с USVM, в этом эксперименте не использовались, и качество на них не измерялось, поскольку модель с такой архитектурой будет иметь значительные проблемы с производительностью, поэтому получение прироста качества за счёт перехода на такую архитектуру на практике может обернуться замедлением работы всей системы и, как следствие, оказаться бесполезным.

\newpage

\section{Дальнейшее развитие} \label{future-works}

Несмотря на неплохие результаты на некоторых имеющихся датасетах, модель можно улучшить во многих местах. Вот список направлений, по которым стоит развивать проект:

\begin{enumerate}
    \item Попробовать провести эксперименты с разными гиперпараметрами нейронной сети: попробовать другие (отличные от 32) значения размерности вектора-состояния вершины, другое количество линейных слоёв в классификаторе и т. д..
    \item Разумеется, стоит попробовать использовать более содержательные из описанных в разделе~\ref{vertex-initial-states} техник построения векторного представления переменных и констант в формуле.
    \item Можно запускать передачу сообщений по графу формулы не только в одном направлении, а сразу во всех, как это было сделано в статье \cite{gnn-for-scheduling-paper}, а после этого использовать не только состояние корневой вершины, а агрегировать информацию сразу со всех вершин.
    \item Чтобы увеличить датасет и повысить обобщающую способность модели, можно попробовать применить разного рода аугментации к формулам в тренировочном датасете.
    \item Если получится научиться проверять на выполнимость относительно произвольные формулы, можно озаботиться поддержкой формул с кванторами.
    \item Поскольку использование модели на практике предполагает не столько предсказательную способность модели, сколько ранжирующую, можно попробовать применить техники из этой области. Например: учитывать косинусное расстояние между вычисляемыми векторами, представляющими выполнимые и невыполнимые формулы, использовать ранжирующую функцию потерь LambdaRank \cite{lambda-rank-paper} или функцию потерь Triplet Loss для задач информационного поиска \cite{triplet-loss-paper-1} \cite{triplet-loss-paper-2}.
    \item Нынешняя версия модели не использует имена переменных, считая, что они ничего толкового не значат. Тем не менее, если речь идёт о модели, используемой для распознавания формул, которые возникают при работе USVM, можно попробовать учитывать имена некоторых переменных, так как они порождаются определённым образом, и в них может содержаться какая-то полезная информация.
    \item Если говорить об использовании модели на практике, стоит отметить необходимость её эффективной реализации. Текущая версия модели написана на языках Python и Kotlin и значительно уступает современным SMT-решателям, написанным на языке C++. Помимо этого можно применить различные техники оптимизации вычислений в нейронных сетях как, например, квантизация.
    \item Наконец, после получения быстрой, показывающей хорошее качество на практике модели, можно озаботиться встраиванием её в работу символьного движка USVM \cite{usvm-diploma}. Для этого нужно будет придумать ряд эвристик для выбора состояния, которые будут учитывать предсказание модели. Изначально такая задача не предполагалась, но она является естественным и логичным продолжением исследования, проведённого в этой работе.
\end{enumerate}
